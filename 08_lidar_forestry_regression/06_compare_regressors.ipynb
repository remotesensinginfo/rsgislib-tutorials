{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a6e2b3-bd96-4b61-8237-b34c74d00709",
   "metadata": {},
   "source": [
    "# Comparing Regressors\n",
    "\n",
    "It is commonly the case that is it no possible to predict which regressor will produce the best results. Therefore, we need to try each of the regressors and compare the results. For this analysis we will not optimise the parameters for the regressors which should be done but this was demonstrated in the previous notebook and significantly increases the compute time for the notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf88c7-ff0b-4a4d-9a43-ec3935cf9d64",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e61c0f-fff1-4f6e-8f50-daa75b38fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import rsgislib.regression.regresssklearn\n",
    "import rsgislib.tools.utils\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d32cc4-fe3a-4dea-9883-dda3b3cdbe08",
   "metadata": {},
   "source": [
    "# 2. Read the input plot data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21719126-d0b3-4080-86ca-9ed710caa91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file as a Pandas data frame - the df variable.\n",
    "df = pandas.read_csv(\"../data/lidar/Forest_Plot_Metrics_LassoLars_Sel.csv\", index_col=0)\n",
    "\n",
    "# Get a list of the columns within the df dataframe\n",
    "cols = list(df.columns)\n",
    "\n",
    "# Get the indepedent predictor column names\n",
    "ind_vars = cols[6:]\n",
    "\n",
    "# Get the dependent response column names\n",
    "dep_vars = cols[3:6]\n",
    "\n",
    "# Get the predictor variables and dependent variables\n",
    "# from the dataframe as numpy arrays\n",
    "x = df[ind_vars].values\n",
    "y = df[dep_vars].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29889690-a0de-4214-8f0d-d8c02dae4f79",
   "metadata": {},
   "source": [
    "# 3. Create output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf0a4d0-d5d6-4bb2-befe-2e66b9a8dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"compare_multivar_reg_outputs\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f6ee3-c760-462a-86eb-c6c3383f5a1d",
   "metadata": {},
   "source": [
    "# 4. Create Data Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e33abd2a-cfa9-40cd-8a86-42424c78762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a data scaler - will be used for some regressors\n",
    "data_scaler = StandardScaler()\n",
    "data_scaler.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018de6b-7fa1-48bb-b650-622acbf36dfb",
   "metadata": {},
   "source": [
    "# 5. KFold Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba52449-2b96-4052-892d-0e6f57e5dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:04, 22.33it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = ExtraTreesRegressor()\n",
    "et_metrics, et_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(\n",
    "    skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None\n",
    ")\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from\n",
    "    # the variable name so it can be used within as part of the output\n",
    "    # file name\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(\n",
    "        dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True\n",
    "    ).lower()\n",
    "\n",
    "    df_metrics = pandas.DataFrame(data=et_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Metrics_ET_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "\n",
    "    df_residuals = pandas.DataFrame(data=et_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Residuals_ET_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_residuals.to_csv(out_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b7553-d7b9-4c31-8ff6-5d3a805cb5cf",
   "metadata": {},
   "source": [
    "# 6. KFold Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3bed8cb-70a0-4e3a-a15b-035769009c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 329.35it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = KernelRidge()\n",
    "kr_metrics, kr_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(\n",
    "    skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None\n",
    ")\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from\n",
    "    # the variable name so it can be used within as part of the output\n",
    "    # file name\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(\n",
    "        dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True\n",
    "    ).lower()\n",
    "\n",
    "    df_metrics = pandas.DataFrame(data=kr_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Metrics_KR_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "\n",
    "    df_residuals = pandas.DataFrame(data=kr_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Residuals_KR_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_residuals.to_csv(out_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f339047-8057-41ba-a62a-e41634170d55",
   "metadata": {},
   "source": [
    "# 7. KFold ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "718d203e-673e-4d88-a35e-5e1dc725fa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 481.23it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = ElasticNet()\n",
    "en_metrics, en_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(\n",
    "    skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None\n",
    ")\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from\n",
    "    # the variable name so it can be used within as part of the output\n",
    "    # file name\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(\n",
    "        dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True\n",
    "    ).lower()\n",
    "\n",
    "    df_metrics = pandas.DataFrame(data=en_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Metrics_EN_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "\n",
    "    df_residuals = pandas.DataFrame(data=en_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Residuals_EN_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_residuals.to_csv(out_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3986545-8d57-4dc8-baa4-7c0f32bd6f10",
   "metadata": {},
   "source": [
    "# 8. KFold K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e191d53-79b8-43fd-908e-968155b5ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 524.48it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = KNeighborsRegressor()\n",
    "knn_metrics, knn_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(\n",
    "    skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=data_scaler\n",
    ")\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from\n",
    "    # the variable name so it can be used within as part of the output\n",
    "    # file name\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(\n",
    "        dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True\n",
    "    ).lower()\n",
    "\n",
    "    df_metrics = pandas.DataFrame(data=knn_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Metrics_KNN_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "\n",
    "    df_residuals = pandas.DataFrame(data=knn_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Residuals_KNN_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_residuals.to_csv(out_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee07c3c-51f5-4cea-91a4-0eedd5d21fdb",
   "metadata": {},
   "source": [
    "# 9. KFold PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5b081f-8adf-432c-a71f-349b35d0df53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 516.43it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = PLSRegression()\n",
    "pls_metrics, pls_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(\n",
    "    skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None\n",
    ")\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from\n",
    "    # the variable name so it can be used within as part of the output\n",
    "    # file name\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(\n",
    "        dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True\n",
    "    ).lower()\n",
    "\n",
    "    df_metrics = pandas.DataFrame(data=pls_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Metrics_PLS_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "\n",
    "    df_residuals = pandas.DataFrame(data=pls_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Residuals_PLS_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_residuals.to_csv(out_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef568289-3573-4569-bb7a-3e32e95fc616",
   "metadata": {},
   "source": [
    "# 10. KFold Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7519297-67ec-4269-917a-c31a2d0f96a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 548.59it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = LinearRegression()\n",
    "ols_metrics, ols_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(\n",
    "    skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None\n",
    ")\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from\n",
    "    # the variable name so it can be used within as part of the output\n",
    "    # file name\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(\n",
    "        dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True\n",
    "    ).lower()\n",
    "\n",
    "    df_metrics = pandas.DataFrame(data=ols_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Metrics_OLS_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "\n",
    "    df_residuals = pandas.DataFrame(data=ols_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"Forest_Plot_Regres_Residuals_OLS_{}.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_residuals.to_csv(out_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b7587-5574-4c8a-b23b-5d5785fd0df1",
   "metadata": {},
   "source": [
    "# 11. Summarising the Regression Statistics\n",
    "\n",
    "The next step is to summarise metrics we have just outputted from the kfold regressions above so we can try and understand which of the regression algorithms has given us the best result. \n",
    "\n",
    "For this analysis we want to summarise each individual set of outputs for each algorithm and dependent variable and then create summary tables we can use to aid the identification of the algorithm to take forward as the **'best'** and for application to the image data. In this case, we will use the following metrics to summarise the results:\n",
    "\n",
    " 1. The coefficient of determination (r2),\n",
    " 2. Root Mean Square Error (RMSE),\n",
    " 3. Normalised Root Mean Square Error (nRMSE),\n",
    " 4. Bias.\n",
    " 5. Normalised Bias\n",
    "\n",
    "The first step is to take all the outputs and merge them into a single table for each depedent variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87522580-2168-477a-9501-1410c4413bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean DBH\n",
      "\tET\n",
      "\tKR\n",
      "\tEN\n",
      "\tKNN\n",
      "\tPLS\n",
      "\tOLS\n",
      "BA / ha\n",
      "\tET\n",
      "\tKR\n",
      "\tEN\n",
      "\tKNN\n",
      "\tPLS\n",
      "\tOLS\n",
      "Vol / ha\n",
      "\tET\n",
      "\tKR\n",
      "\tEN\n",
      "\tKNN\n",
      "\tPLS\n",
      "\tOLS\n"
     ]
    }
   ],
   "source": [
    "regress_alg = [\"ET\", \"KR\", \"EN\", \"KNN\", \"PLS\", \"OLS\"]\n",
    "regress_metrics = [\n",
    "    et_metrics,\n",
    "    kr_metrics,\n",
    "    en_metrics,\n",
    "    knn_metrics,\n",
    "    pls_metrics,\n",
    "    ols_metrics,\n",
    "]\n",
    "\n",
    "# Using the aggregate function in Pandas we can specify a list of summary statistics for each column\n",
    "regrs_metrics_sum_stats = {\n",
    "    \"r2\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"explained_variance_score\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"median_absolute_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"mean_absolute_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"mean_squared_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"root_mean_squared_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"norm_root_mean_squared_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"bias\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"norm_bias\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"bias_squared\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"variance\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"noise\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "}\n",
    "\n",
    "out_summary_stats = dict()\n",
    "\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    print(dep_var)\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(\n",
    "        dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True\n",
    "    ).lower()\n",
    "\n",
    "    rmse_sum_stats = dict()\n",
    "    rmse_sum_stats[\"mean\"] = list()\n",
    "    rmse_sum_stats[\"median\"] = list()\n",
    "    rmse_sum_stats[\"std\"] = list()\n",
    "    rmse_sum_stats[\"stderr\"] = list()\n",
    "    rmse_sum_stats[\"conf95\"] = list()\n",
    "\n",
    "    nrmse_sum_stats = dict()\n",
    "    nrmse_sum_stats[\"mean\"] = list()\n",
    "    nrmse_sum_stats[\"median\"] = list()\n",
    "    nrmse_sum_stats[\"std\"] = list()\n",
    "    nrmse_sum_stats[\"stderr\"] = list()\n",
    "    nrmse_sum_stats[\"conf95\"] = list()\n",
    "\n",
    "    r2_sum_stats = dict()\n",
    "    r2_sum_stats[\"mean\"] = list()\n",
    "    r2_sum_stats[\"median\"] = list()\n",
    "    r2_sum_stats[\"std\"] = list()\n",
    "    r2_sum_stats[\"stderr\"] = list()\n",
    "    r2_sum_stats[\"conf95\"] = list()\n",
    "\n",
    "    bias_sum_stats = dict()\n",
    "    bias_sum_stats[\"mean\"] = list()\n",
    "    bias_sum_stats[\"median\"] = list()\n",
    "    bias_sum_stats[\"std\"] = list()\n",
    "    bias_sum_stats[\"stderr\"] = list()\n",
    "    bias_sum_stats[\"conf95\"] = list()\n",
    "\n",
    "    nbias_sum_stats = dict()\n",
    "    nbias_sum_stats[\"mean\"] = list()\n",
    "    nbias_sum_stats[\"median\"] = list()\n",
    "    nbias_sum_stats[\"std\"] = list()\n",
    "    nbias_sum_stats[\"stderr\"] = list()\n",
    "    nbias_sum_stats[\"conf95\"] = list()\n",
    "\n",
    "    for metrics, alg in zip(regress_metrics, regress_alg):\n",
    "        print(f\"\\t{alg}\")\n",
    "        # Create pandas dataframe for the metrics.\n",
    "        df_var_metrics = pandas.DataFrame(data=metrics[i])\n",
    "        # Get the number of samples\n",
    "        n_smps = df_var_metrics.shape[0]\n",
    "        # Calculate the summary statistics (see regrs_metrics_sum_stats\n",
    "        # for the list of stats to be calculated\n",
    "        df_var_sum_stats = df_var_metrics.agg(regrs_metrics_sum_stats).T\n",
    "\n",
    "        # Calculate additional summary statistics:\n",
    "        # Stand Error and 95th and 99th confidence intervals\n",
    "        df_var_sum_stats[\"stderr\"] = df_var_sum_stats[\"std\"] / numpy.sqrt(n_smps)\n",
    "        df_var_sum_stats[\"conf95\"] = 1.960 * df_var_sum_stats[\"stderr\"]\n",
    "        df_var_sum_stats[\"conf99\"] = 2.576 * df_var_sum_stats[\"stderr\"]\n",
    "\n",
    "        # Transpose the dataframe to make it easier to read.\n",
    "        df_var_sum_stats = df_var_sum_stats.T\n",
    "\n",
    "        # Add RMSE values for overall summary statistics table\n",
    "        rmse_sum_stats[\"mean\"].append(\n",
    "            df_var_sum_stats[\"root_mean_squared_error\"][\"mean\"]\n",
    "        )\n",
    "        rmse_sum_stats[\"median\"].append(\n",
    "            df_var_sum_stats[\"root_mean_squared_error\"][\"median\"]\n",
    "        )\n",
    "        rmse_sum_stats[\"std\"].append(df_var_sum_stats[\"root_mean_squared_error\"][\"std\"])\n",
    "        rmse_sum_stats[\"stderr\"].append(\n",
    "            df_var_sum_stats[\"root_mean_squared_error\"][\"stderr\"]\n",
    "        )\n",
    "        rmse_sum_stats[\"conf95\"].append(\n",
    "            df_var_sum_stats[\"root_mean_squared_error\"][\"conf95\"]\n",
    "        )\n",
    "\n",
    "        # Add normalised RMSE values for overall summary statistics table\n",
    "        nrmse_sum_stats[\"mean\"].append(\n",
    "            df_var_sum_stats[\"norm_root_mean_squared_error\"][\"mean\"]\n",
    "        )\n",
    "        nrmse_sum_stats[\"median\"].append(\n",
    "            df_var_sum_stats[\"norm_root_mean_squared_error\"][\"median\"]\n",
    "        )\n",
    "        nrmse_sum_stats[\"std\"].append(\n",
    "            df_var_sum_stats[\"norm_root_mean_squared_error\"][\"std\"]\n",
    "        )\n",
    "        nrmse_sum_stats[\"stderr\"].append(\n",
    "            df_var_sum_stats[\"norm_root_mean_squared_error\"][\"stderr\"]\n",
    "        )\n",
    "        nrmse_sum_stats[\"conf95\"].append(\n",
    "            df_var_sum_stats[\"norm_root_mean_squared_error\"][\"conf95\"]\n",
    "        )\n",
    "\n",
    "        # Add r2 values for overall summary statistics table\n",
    "        r2_sum_stats[\"mean\"].append(df_var_sum_stats[\"r2\"][\"mean\"])\n",
    "        r2_sum_stats[\"median\"].append(df_var_sum_stats[\"r2\"][\"median\"])\n",
    "        r2_sum_stats[\"std\"].append(df_var_sum_stats[\"r2\"][\"std\"])\n",
    "        r2_sum_stats[\"stderr\"].append(df_var_sum_stats[\"r2\"][\"stderr\"])\n",
    "        r2_sum_stats[\"conf95\"].append(df_var_sum_stats[\"r2\"][\"conf95\"])\n",
    "\n",
    "        # Add bias values for overall summary statistics table\n",
    "        bias_sum_stats[\"mean\"].append(df_var_sum_stats[\"bias\"][\"mean\"])\n",
    "        bias_sum_stats[\"median\"].append(df_var_sum_stats[\"bias\"][\"median\"])\n",
    "        bias_sum_stats[\"std\"].append(df_var_sum_stats[\"bias\"][\"std\"])\n",
    "        bias_sum_stats[\"stderr\"].append(df_var_sum_stats[\"bias\"][\"stderr\"])\n",
    "        bias_sum_stats[\"conf95\"].append(df_var_sum_stats[\"bias\"][\"conf95\"])\n",
    "\n",
    "        # Add normalised bias values for overall summary statistics table\n",
    "        nbias_sum_stats[\"mean\"].append(df_var_sum_stats[\"norm_bias\"][\"mean\"])\n",
    "        nbias_sum_stats[\"median\"].append(df_var_sum_stats[\"norm_bias\"][\"median\"])\n",
    "        nbias_sum_stats[\"std\"].append(df_var_sum_stats[\"norm_bias\"][\"std\"])\n",
    "        nbias_sum_stats[\"stderr\"].append(df_var_sum_stats[\"norm_bias\"][\"stderr\"])\n",
    "        nbias_sum_stats[\"conf95\"].append(df_var_sum_stats[\"norm_bias\"][\"conf95\"])\n",
    "\n",
    "    # Create a pandas dataframe and write out a CSV file for the RMSE over summary\n",
    "    df_rmse_sum_stats = pandas.DataFrame(data=rmse_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"{}_rmse_overall_summary.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_rmse_sum_stats.to_csv(out_csv_file)\n",
    "\n",
    "    # Create a pandas dataframe and write out a CSV file for the normalised RMSE over summary\n",
    "    df_nrmse_sum_stats = pandas.DataFrame(data=nrmse_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"{}_nrmse_overall_summary.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_nrmse_sum_stats.to_csv(out_csv_file)\n",
    "\n",
    "    # Create a pandas dataframe and write out a CSV file for the r2 over summary\n",
    "    df_r2_sum_stats = pandas.DataFrame(data=r2_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"{}_r2_overall_summary.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_r2_sum_stats.to_csv(out_csv_file)\n",
    "\n",
    "    # Create a pandas dataframe and write out a CSV file for the bias over summary\n",
    "    df_bias_sum_stats = pandas.DataFrame(data=bias_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"{}_bias_overall_summary.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_bias_sum_stats.to_csv(out_csv_file)\n",
    "\n",
    "    # Create a pandas dataframe and write out a CSV file for the normalised bias over summary\n",
    "    df_nbias_sum_stats = pandas.DataFrame(data=nbias_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(\n",
    "        out_dir, \"{}_nbias_overall_summary.csv\".format(dep_var_chk)\n",
    "    )\n",
    "    df_nbias_sum_stats.to_csv(out_csv_file)\n",
    "\n",
    "    out_summary_stats[dep_var] = {\n",
    "        \"rmse\": df_rmse_sum_stats,\n",
    "        \"nrmse\": df_nrmse_sum_stats,\n",
    "        \"r2\": df_r2_sum_stats,\n",
    "        \"bias\": df_bias_sum_stats,\n",
    "        \"nbias\": df_nbias_sum_stats,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a663c-5671-4981-b4cb-e3d31e524a81",
   "metadata": {
    "tags": []
   },
   "source": [
    "The previous code created summary files and dataframes, lets now format those into tables for us to interpret, including rounding the numbers to make them more readable. We will also save those tables to CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d7f9a2-074a-4307-83d6-4777ecd5e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean DBH\n",
      "\trmse\n",
      "\tnrmse\n",
      "\tr2\n",
      "\tbias\n",
      "\tnbias\n",
      "BA / ha\n",
      "\trmse\n",
      "\tnrmse\n",
      "\tr2\n",
      "\tbias\n",
      "\tnbias\n",
      "Vol / ha\n",
      "\trmse\n",
      "\tnrmse\n",
      "\tr2\n",
      "\tbias\n",
      "\tnbias\n"
     ]
    }
   ],
   "source": [
    "summary_median_tabs = dict()\n",
    "\n",
    "for dep_var in dep_vars:\n",
    "    print(dep_var)\n",
    "    sum_stats = dict()\n",
    "    for stat in out_summary_stats[dep_var]:\n",
    "        print(f\"\\t{stat}\")\n",
    "        var_df = out_summary_stats[dep_var][stat]\n",
    "        sum_stats[stat] = var_df[\"median\"].round(3)\n",
    "    summary_median_tabs[dep_var] = pandas.DataFrame(data=sum_stats)\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(\n",
    "        dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True\n",
    "    ).lower()\n",
    "    out_csv_file = os.path.join(out_dir, f\"{dep_var_chk}_alg_compare_stats.csv\")\n",
    "    summary_median_tabs[dep_var].to_csv(out_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9983b33-7ca8-434c-acfe-5357425ea47c",
   "metadata": {},
   "source": [
    "Now lets view those summary tables, sorted by the normalised RMSE (try sorting by the other columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a6285e-a495-4e02-90da-6d967a8a1d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>bias</th>\n",
       "      <th>nbias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>3.104</td>\n",
       "      <td>17.893</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>3.103</td>\n",
       "      <td>18.342</td>\n",
       "      <td>0.752</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>3.218</td>\n",
       "      <td>18.817</td>\n",
       "      <td>0.732</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>-2.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>3.332</td>\n",
       "      <td>19.073</td>\n",
       "      <td>0.741</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>3.460</td>\n",
       "      <td>20.226</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>3.473</td>\n",
       "      <td>20.253</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rmse   nrmse     r2   bias  nbias\n",
       "OLS  3.104  17.893  0.754  0.122  0.702\n",
       "ET   3.103  18.342  0.752 -0.137 -0.763\n",
       "KNN  3.218  18.817  0.732 -0.421 -2.375\n",
       "KR   3.332  19.073  0.741 -0.060 -0.347\n",
       "PLS  3.460  20.226  0.694  0.010  0.046\n",
       "EN   3.473  20.253  0.691  0.017  0.102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_median_tabs[\"Mean DBH\"].sort_values(\"nrmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "938096f3-7655-4271-895f-b5721cdf9471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>bias</th>\n",
       "      <th>nbias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>7.458</td>\n",
       "      <td>20.543</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>7.450</td>\n",
       "      <td>20.933</td>\n",
       "      <td>0.838</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>7.412</td>\n",
       "      <td>21.102</td>\n",
       "      <td>0.843</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>7.581</td>\n",
       "      <td>21.532</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>8.064</td>\n",
       "      <td>23.224</td>\n",
       "      <td>0.806</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-1.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>8.426</td>\n",
       "      <td>23.832</td>\n",
       "      <td>0.795</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rmse   nrmse     r2   bias  nbias\n",
       "ET   7.458  20.543  0.840  0.023  0.066\n",
       "PLS  7.450  20.933  0.838 -0.085 -0.238\n",
       "KR   7.412  21.102  0.843 -0.204 -0.577\n",
       "OLS  7.581  21.532  0.835 -0.224 -0.641\n",
       "KNN  8.064  23.224  0.806 -0.658 -1.830\n",
       "EN   8.426  23.832  0.795 -0.009 -0.018"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_median_tabs[\"BA / ha\"].sort_values(\"nrmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca45d594-0c9a-42c7-b705-6e616b76a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>bias</th>\n",
       "      <th>nbias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>59.902</td>\n",
       "      <td>21.364</td>\n",
       "      <td>0.902</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>63.010</td>\n",
       "      <td>22.419</td>\n",
       "      <td>0.899</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>-0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>60.553</td>\n",
       "      <td>22.527</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1.324</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>63.674</td>\n",
       "      <td>23.178</td>\n",
       "      <td>0.895</td>\n",
       "      <td>-1.660</td>\n",
       "      <td>-0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>67.262</td>\n",
       "      <td>24.705</td>\n",
       "      <td>0.879</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>-0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>72.696</td>\n",
       "      <td>26.438</td>\n",
       "      <td>0.861</td>\n",
       "      <td>-14.276</td>\n",
       "      <td>-5.165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rmse   nrmse     r2    bias  nbias\n",
       "ET   59.902  21.364  0.902  -0.970 -0.357\n",
       "KR   63.010  22.419  0.899  -0.719 -0.262\n",
       "EN   60.553  22.527  0.896   1.324  0.515\n",
       "OLS  63.674  23.178  0.895  -1.660 -0.538\n",
       "PLS  67.262  24.705  0.879  -0.378 -0.134\n",
       "KNN  72.696  26.438  0.861 -14.276 -5.165"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_median_tabs[\"Vol / ha\"].sort_values(\"nrmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c23ba0-5ca4-4dea-9c9c-dc6f7191fb11",
   "metadata": {},
   "source": [
    "# 12. So, which is 'best'\n",
    "\n",
    "*Note. Your results might differ slightly from mine as the kfold will produce slightly different results for each run as the splits will be different.*\n",
    "\n",
    "Looking at these tables we can see that for Mean DBH the Extra Trees Regressor has produced the best result with a nRMSE of 17.8 % following by Linear Regression with a nRMSE of 18.9 %. For Basal Area, Extra Trees provided the best result (nRMSE: 21.0 %) followed by PLSRegression (nRMSE: 21.0 %). While for stand volume Extra Trees also provided the best result (NRMSE: 22.3 %) with the KernelRidge regressor (nRMSE: 22.3 %). \n",
    "\n",
    "Therefore we would take forward the Extra Trees result as the regressor to use for further analysis. However, it is worth noting that \n",
    "\n",
    " 1. We did not optimise the parameters of the algorithms and if we had done so then the results might have been different - why don't you try to implement this yourself?\n",
    " 2. The LinearRegressor (OLS) is a much similar model and also produced results which are similar to those of the other algorithms and while it has not produced the best result is it often deseriable to use a simpler model.\n",
    " 3. Becareful of using a model for where inputs are outside of the range of values which used to train the model as there is no guareentee that the results will be valid and it some cases the outputs completely wrong. However, simpler linear models are less likely to produce values which are completely crazy and therefore might be desriable from that point of view.\n",
    "\n",
    "Where you have results which are close then it might also be useful to consider the residuals visualing those to consider the bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623203b-33ae-4e73-bf99-e9142ba39a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
